{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BlUmfHsYJzAE",
    "outputId": "b7a69c18-e06a-49f9-921d-840a913f7df1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
      "    from pip._internal.cli.main import main\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 3, in <module>\n",
      "    import locale\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\n",
      "KeyboardInterrupt\n",
      "^C\n",
      "Collecting wikipedia-api\n",
      "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from wikipedia-api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2024.2.2)\n",
      "Installing collected packages: wikipedia-api\n",
      "Successfully installed wikipedia-api-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install wikipedia-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388,
     "referenced_widgets": [
      "7681f6fb425a4fb396f0a39c7fd73969",
      "5ee619f3e756455389c7246bdc11874c",
      "8ca5509fe5a44e5281e34dd1705af86c",
      "31a142393be3413cbb301eb8a9d80f6d",
      "85261ee283af4e78a058775c39ce42bb",
      "6bf7db26acdb44e897e959f01c5fb1aa",
      "2d1b396643cd45078535c4ad6a70f667",
      "ce861805789d4c50a778cd4bb84897c7",
      "445bb0fdb7a84750b8f15e6c8a6cad41",
      "0d8f6cacc02c432784bb1843b86fe36e",
      "0dd3b0fec478440d91d9d84a72ab0280"
     ]
    },
    "id": "qrh0GmpBKbh5",
    "outputId": "2a5fcde0-776d-4662-b4d0-ac55e0850349"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wikipediaapi\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the keyword extractor model\n",
    "class KeywordExtractor(nn.Module):\n",
    "    def __init__(self, bert_model_name, lstm_hidden_dim, attention_units, output_dim):\n",
    "        super(KeywordExtractor, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.lstm = nn.LSTM(self.bert.config.hidden_size, lstm_hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.W1 = nn.Linear(lstm_hidden_dim * 2, attention_units)\n",
    "        self.W2 = nn.Linear(attention_units, 1)\n",
    "        self.fc = nn.Linear(lstm_hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sequence_output = bert_outputs.last_hidden_state\n",
    "        H, _ = self.lstm(sequence_output)\n",
    "        u = torch.tanh(self.W1(H))\n",
    "        attention_scores = self.W2(u).squeeze(-1)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "        context_vector = torch.bmm(attention_weights.unsqueeze(1), H).squeeze(1)\n",
    "        output = self.fc(H)  # Token-level classification\n",
    "        return output, attention_weights\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess_text(text, tokenizer, max_seq_length=512):\n",
    "    tokens = tokenizer(text, max_length=max_seq_length, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    input_ids = tokens.input_ids\n",
    "    attention_mask = tokens.attention_mask\n",
    "    return input_ids, attention_mask\n",
    "\n",
    "# Load the provided dataset\n",
    "def load_dataset():\n",
    "    # Sample dataset of 100 labeled sentences\n",
    "    dataset = [\n",
    "    {\"text\": \"Machine learning algorithms can classify data efficiently\", \"labels\": [1, 1, 1, 0, 1, 0, 0,]},\n",
    "    {\"text\": \"Deep learning models can learn from large amounts of unlabeled data\", \"labels\": [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]},\n",
    "    {\"text\": \"Supervised learning requires labeled datasets for training\", \"labels\": [1, 1, 0, 1, 0, 0, 0]},\n",
    "    {\"text\": \"Neural networks consist of interconnected layers of nodes\", \"labels\": [1, 1, 0, 0, 1, 0, 0, 1]},\n",
    "    {\"text\": \"Unsupervised learning techniques aim to find hidden patterns in data\", \"labels\": [1, 1, 0, 0, 0, 0, 0, 1, 0, 0]},\n",
    "    {\"text\": \"Support vector machines are effective for classification tasks\", \"labels\": [1, 1, 1, 0, 0, 0, 1, 0]},\n",
    "    {\"text\": \"Reinforcement learning agents learn from feedback received from their environment\", \"labels\": [1, 1, 0, 0, 0, 1, 0, 0, 0, 0]},\n",
    "    {\"text\": \"Feature engineering is crucial for improving model performance\", \"labels\": [1, 1, 0, 0, 0, 0, 0, 1]},\n",
    "    {\"text\": \"Decision trees are a type of supervised learning algorithm\", \"labels\": [1, 1, 0, 0, 0, 0, 1, 1, 0]},\n",
    "    {\"text\": \"Natural language processing enables computers to understand human language\", \"labels\": [1, 1, 1, 0, 0, 0, 0, 1, 1]}]\n",
    "\n",
    "\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Combine datasets\n",
    "def combine_datasets(wikipedia_articles, labeled_sentences):\n",
    "    combined_data = []\n",
    "    combined_data.extend(wikipedia_articles)\n",
    "    combined_data.extend(labeled_sentences)\n",
    "    return combined_data\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, criterion, optimizer, train_data, tokenizer, max_seq_length=512, num_epochs=5, batch_size=8):\n",
    "    # Split data into train and validation sets\n",
    "    train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_dataset = CustomDataset(train_data, tokenizer, max_seq_length)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_dataset = CustomDataset(val_data, tokenizer, max_seq_length)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            batch_input_ids = batch['input_ids'].to(device)\n",
    "            batch_attention_mask = batch['attention_mask'].to(device)\n",
    "            batch_labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(batch_input_ids, batch_attention_mask)\n",
    "            loss = criterion(outputs.view(-1), batch_labels.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * batch_input_ids.size(0)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_loss / len(train_dataset)}')\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        for batch in val_loader:\n",
    "            batch_input_ids = batch['input_ids'].to(device)\n",
    "            batch_attention_mask = batch['attention_mask'].to(device)\n",
    "            batch_labels = batch['labels'].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs, _ = model(batch_input_ids, batch_attention_mask)\n",
    "                loss = criterion(outputs.view(-1), batch_labels.view(-1))\n",
    "                val_loss += loss.item() * batch_input_ids.size(0)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Val Loss: {val_loss / len(val_dataset)}')\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, max_seq_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "        # Convert each element of data into a dictionary\n",
    "        self.process_data()\n",
    "\n",
    "    def process_data(self):\n",
    "        processed_data = []\n",
    "        for item in self.data:\n",
    "            # Convert item to a dictionary if it's not already\n",
    "            if isinstance(item, dict):\n",
    "                processed_data.append(item)\n",
    "            else:\n",
    "                processed_data.append({'text': str(item), 'labels': []})  # Assuming labels are empty for non-dictionary items\n",
    "        self.data = processed_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.data[idx]\n",
    "\n",
    "        text = example['text']\n",
    "        label = example['labels']\n",
    "\n",
    "        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_seq_length, return_tensors='pt')\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "\n",
    "        # Pad labels to match max_seq_length\n",
    "        padded_label = label + [0] * (self.max_seq_length - len(label))\n",
    "        label_tensor = torch.tensor(padded_label, dtype=torch.float32)\n",
    "\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': label_tensor}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract keywords\n",
    "def extract_keywords(text, model, tokenizer, threshold=0, max_seq_length=512):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    input_ids, attention_mask = preprocess_text(text, tokenizer, max_seq_length)\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output, _ = model(input_ids, attention_mask)\n",
    "    predictions = torch.sigmoid(output)\n",
    "\n",
    "    # Get the tokens exceeding the threshold\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
    "    keywords = [(token, pred.item()) for token, pred in zip(tokens, predictions.squeeze()) if pred.item() > threshold]\n",
    "\n",
    "    print(\"Keywords:\", keywords)\n",
    "\n",
    "    return keywords\n",
    "# Function to scrape Wikipedia articles\n",
    "def scrape_wikipedia_articles(categories, max_articles=10):\n",
    "    wiki_wiki = wikipediaapi.Wikipedia('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36')\n",
    "    articles = []\n",
    "    labels = []\n",
    "\n",
    "    for category in categories:\n",
    "        cat = wiki_wiki.page(f\"Category:{category}\")\n",
    "        pages = cat.categorymembers.values()\n",
    "        for page in pages:\n",
    "            if len(articles) >= max_articles:\n",
    "                break\n",
    "            if page.ns == 0:  # only get articles (namespace 0)\n",
    "                text = page.text\n",
    "                soup = BeautifulSoup(text, 'html.parser')\n",
    "                cleaned_text = soup.get_text()\n",
    "                tokens = cleaned_text.split()\n",
    "                if len(tokens) > 0:\n",
    "                    articles.append({'text': cleaned_text, 'labels': [0] * len(tokens)})  # Placeholder labels\n",
    "                    labels.append([0] * len(tokens))  # Placeholder labels\n",
    "\n",
    "    return articles, labels\n",
    "\n",
    "\n",
    "def main(custom_text):\n",
    "    # Stage 1: Pre-training on Wikipedia Data\n",
    "    bert_model_name = 'bert-base-uncased'\n",
    "    lstm_hidden_dim = 128\n",
    "    attention_units = 64\n",
    "    output_dim = 1\n",
    "    num_epochs_stage1 = 5\n",
    "    batch_size = 8\n",
    "\n",
    "    # Load BERT tokenizer\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(bert_model_name)\n",
    "\n",
    "    # Scrape Wikipedia articles\n",
    "    categories = [\"Machine_learning\", \"Natural_language_processing\"]\n",
    "    articles, labels = scrape_wikipedia_articles(categories, max_articles=1000)\n",
    "\n",
    "    # Combine Wikipedia data\n",
    "    combined_wiki_data = combine_datasets(articles, labels)\n",
    "\n",
    "    # Initialize model, criterion, and optimizer\n",
    "    model = KeywordExtractor(bert_model_name, lstm_hidden_dim, attention_units, output_dim)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model on Wikipedia data\n",
    "    train_model(model, criterion, optimizer, combined_wiki_data, tokenizer, num_epochs=num_epochs_stage1, batch_size=batch_size)\n",
    "\n",
    "    # Stage 2: Fine-tuning on Custom Data\n",
    "    # Load the provided dataset\n",
    "    labeled_sentences = load_dataset()\n",
    "\n",
    "    # Combine custom data\n",
    "    combined_custom_data = labeled_sentences\n",
    "\n",
    "    # Fine-tune the model on custom data\n",
    "    train_model(model, criterion, optimizer, combined_custom_data, tokenizer, num_epochs=num_epochs_stage2, batch_size=batch_size)\n",
    "\n",
    "    # Extract keywords\n",
    "    keywords = extract_keywords(custom_text, model, tokenizer, threshold=0, max_seq_length=512)\n",
    "\n",
    "    # Sort the keywords by descending order of importance\n",
    "    sorted_keywords = sorted(keywords, key=lambda x: x[1], reverse=True)\n",
    "    top_keywords = sorted_keywords[:10]\n",
    "\n",
    "    print(\"Top Keywords:\", top_keywords)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    custom_text = \"Before Machine learning was invented, many tasks were difficult\"\n",
    "    main(custom_text)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    custom_text = \"Before Machine learning was invented,many tasks were difficult\"\n",
    "    main(custom_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fshUG3ohKjEV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1Aazdu2KrVO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d8f6cacc02c432784bb1843b86fe36e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0dd3b0fec478440d91d9d84a72ab0280": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d1b396643cd45078535c4ad6a70f667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31a142393be3413cbb301eb8a9d80f6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d8f6cacc02c432784bb1843b86fe36e",
      "placeholder": "​",
      "style": "IPY_MODEL_0dd3b0fec478440d91d9d84a72ab0280",
      "value": " 440M/440M [00:05&lt;00:00, 64.7MB/s]"
     }
    },
    "445bb0fdb7a84750b8f15e6c8a6cad41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5ee619f3e756455389c7246bdc11874c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bf7db26acdb44e897e959f01c5fb1aa",
      "placeholder": "​",
      "style": "IPY_MODEL_2d1b396643cd45078535c4ad6a70f667",
      "value": "model.safetensors: 100%"
     }
    },
    "6bf7db26acdb44e897e959f01c5fb1aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7681f6fb425a4fb396f0a39c7fd73969": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5ee619f3e756455389c7246bdc11874c",
       "IPY_MODEL_8ca5509fe5a44e5281e34dd1705af86c",
       "IPY_MODEL_31a142393be3413cbb301eb8a9d80f6d"
      ],
      "layout": "IPY_MODEL_85261ee283af4e78a058775c39ce42bb"
     }
    },
    "85261ee283af4e78a058775c39ce42bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ca5509fe5a44e5281e34dd1705af86c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce861805789d4c50a778cd4bb84897c7",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_445bb0fdb7a84750b8f15e6c8a6cad41",
      "value": 440449768
     }
    },
    "ce861805789d4c50a778cd4bb84897c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
