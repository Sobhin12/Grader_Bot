{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_CKK1kSoPEu",
        "outputId": "9a177414-2d67-4522-c547-972dff6d9c89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia_API-0.6.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from wikipedia-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2024.6.2)\n",
            "Installing collected packages: wikipedia-api\n",
            "Successfully installed wikipedia-api-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install wikipedia-api\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n"
      ],
      "metadata": {
        "id": "Q14I3wvmsC5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import BertTokenizerFast, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "import wikipediaapi\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Define the keyword extractor model\n",
        "class KeywordExtractor(nn.Module):\n",
        "    def __init__(self, bert_model_name, lstm_hidden_dim, attention_units, output_dim):\n",
        "        super(KeywordExtractor, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
        "        self.lstm = nn.LSTM(self.bert.config.hidden_size, lstm_hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.W1 = nn.Linear(lstm_hidden_dim * 2, attention_units)\n",
        "        self.W2 = nn.Linear(attention_units, 1)\n",
        "        self.fc = nn.Linear(lstm_hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        with torch.no_grad():\n",
        "            bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = bert_outputs.last_hidden_state\n",
        "        H, _ = self.lstm(sequence_output)\n",
        "        u = torch.tanh(self.W1(H))\n",
        "        attention_scores = self.W2(u).squeeze(-1)\n",
        "        attention_weights = torch.softmax(attention_scores, dim=-1)\n",
        "        context_vector = torch.bmm(attention_weights.unsqueeze(1), H).squeeze(1)\n",
        "        output = self.fc(H)  # Token-level classification\n",
        "        return output, attention_weights\n",
        "\n",
        "# Preprocess text\n",
        "# Preprocess text\n",
        "# Preprocess text\n",
        "# Preprocess text\n",
        "def preprocess_text(text, tokenizer, max_seq_length=512):\n",
        "    tokens = tokenizer(text, max_length=max_seq_length, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    input_ids = tokens.input_ids\n",
        "    attention_mask = tokens.attention_mask\n",
        "    return input_ids, attention_mask\n",
        "\n",
        "\n",
        "# Scrape Wikipedia articles and extract keywords\n",
        "# Scrape Wikipedia articles and extract keywords\n",
        "def scrape_wikipedia_articles(categories, max_articles=10):\n",
        "    user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
        "    wiki_wiki = wikipediaapi.Wikipedia(language='en', extract_format=wikipediaapi.ExtractFormat.HTML, user_agent=user_agent)\n",
        "    articles = []\n",
        "    labels = []\n",
        "    for category in categories:\n",
        "        category_page = wiki_wiki.page(\"Category:\" + category)\n",
        "        count = 0\n",
        "        for title, page in category_page.categorymembers.items():\n",
        "            if count >= max_articles:\n",
        "                break\n",
        "            if page.exists() and not page.namespace == wikipediaapi.Namespace.CATEGORY:\n",
        "                soup = BeautifulSoup(page.text, 'html.parser')\n",
        "                first_paragraph = soup.p\n",
        "                if first_paragraph:\n",
        "                    text = first_paragraph.get_text()\n",
        "                    hyperlinks = [a.get_text() for a in first_paragraph.find_all('a')]\n",
        "                    articles.append(text)\n",
        "                    label = [1 if word in hyperlinks else 0 for word in text.split()]\n",
        "                    labels.append(label[:512])  # Truncate labels to match input sequence length\n",
        "                    count += 1\n",
        "    return articles, labels\n",
        "\n",
        "# Train the model\n",
        "# Train the model\n",
        "# Train the model\n",
        "# Train the model\n",
        "def train_model(model, criterion, optimizer, train_data, train_labels, tokenizer, max_seq_length=512, num_epochs=5, batch_size=8):\n",
        "    model.train()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    train_dataset = CustomDataset(train_data, train_labels, tokenizer, max_seq_length)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            batch_input_ids = batch['input_ids'].to(device)\n",
        "            batch_attention_mask = batch['attention_mask'].to(device)\n",
        "            batch_labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs, _ = model(batch_input_ids, batch_attention_mask)\n",
        "            loss = criterion(outputs.view(-1), batch_labels.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() * batch_input_ids.size(0)\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_dataset)}')\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_seq_length):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = max_seq_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_seq_length, return_tensors='pt')\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "\n",
        "        # Pad labels to match max_seq_length\n",
        "        padded_label = label + [0] * (self.max_seq_length - len(label))\n",
        "        label_tensor = torch.tensor(padded_label, dtype=torch.float32)\n",
        "\n",
        "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': label_tensor}\n",
        "\n",
        "\n",
        "\n",
        "# Extract keywords\n",
        "# Extract keywords\n",
        "# Extract keywords\n",
        "# Extract keywords\n",
        "# Extract keywords\n",
        "def extract_keywords(text, model, tokenizer, threshold=0, max_seq_length=512):\n",
        "    model.eval()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    input_ids, attention_mask = preprocess_text(text, tokenizer, max_seq_length)\n",
        "    print(\"Input IDs shape:\", input_ids.shape)\n",
        "    print(\"Attention mask shape:\", attention_mask.shape)\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output, _ = model(input_ids, attention_mask)\n",
        "    predictions = torch.sigmoid(output)\n",
        "\n",
        "    # Get the tokens exceeding the threshold\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze().tolist())\n",
        "    keywords = [(token, pred.item()) for token, pred in zip(tokens, predictions.squeeze()) if pred.item() > threshold]\n",
        "\n",
        "    print(\"predictions\",predictions)\n",
        "    print(\"Tokens:\", tokens)\n",
        "    print(\"Keywords:\", keywords)\n",
        "\n",
        "    return keywords\n"
      ],
      "metadata": {
        "id": "rL58ce1BpB5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(custom_text):\n",
        "    # Define parameters\n",
        "    bert_model_name = 'bert-base-uncased'\n",
        "    lstm_hidden_dim = 128\n",
        "    attention_units = 64\n",
        "    output_dim = 1\n",
        "    num_epochs = 10\n",
        "    batch_size = 8\n",
        "\n",
        "    # Load BERT tokenizer\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(bert_model_name)\n",
        "\n",
        "    # Scrape Wikipedia articles\n",
        "    categories = [\"Machine_learning\", \"Natural_language_processing\"]\n",
        "    articles, labels = scrape_wikipedia_articles(categories, max_articles=1000)\n",
        "\n",
        "    # Split data into train and test sets\n",
        "    train_data, test_data, train_labels, test_labels = train_test_split(articles, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize model, criterion, and optimizer\n",
        "    model = KeywordExtractor(bert_model_name, lstm_hidden_dim, attention_units, output_dim)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    train_model(model, criterion, optimizer, train_data, train_labels, tokenizer, num_epochs=num_epochs, batch_size=batch_size)\n",
        "\n",
        "    # Extract keywords\n",
        "    keywords = extract_keywords(custom_text, model, tokenizer, threshold=0, max_seq_length=512)\n",
        "\n",
        "\n",
        "\n",
        "    # Sort the keywords by descending order of importance\n",
        "    sorted_keywords = sorted(keywords, key=lambda x: x[1], reverse=True)\n",
        "    top_keywords = sorted_keywords[:10]\n",
        "\n",
        "    print(\"Top Keywords:\", top_keywords)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3wW7j6ZLpR0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    custom_text = \"BERT is a powerful model for natural language understanding. It has revolutionized many NLP tasks.\"\n",
        "    main(custom_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp7Bx_Q2pVUy",
        "outputId": "3e83ac57-ca80-41cf-d952-6f3f9c71657c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.05450168617521924\n",
            "Epoch 2/10, Loss: 0.00023904201208554596\n",
            "Epoch 3/10, Loss: 0.00016148818786002996\n",
            "Epoch 4/10, Loss: 0.00011995375005668298\n",
            "Epoch 5/10, Loss: 9.324607530856408e-05\n",
            "Epoch 6/10, Loss: 7.484527035600189e-05\n",
            "Epoch 7/10, Loss: 6.130578082507056e-05\n",
            "Epoch 8/10, Loss: 5.183335813569885e-05\n",
            "Epoch 9/10, Loss: 4.436436642198204e-05\n",
            "Epoch 10/10, Loss: 3.860919397173589e-05\n",
            "Input IDs shape: torch.Size([1, 512])\n",
            "Attention mask shape: torch.Size([1, 512])\n",
            "predictions tensor([[[1.4485e-03],\n",
            "         [2.3213e-04],\n",
            "         [5.8635e-05],\n",
            "         [3.7038e-05],\n",
            "         [3.2713e-05],\n",
            "         [3.2063e-05],\n",
            "         [3.2949e-05],\n",
            "         [3.1819e-05],\n",
            "         [3.3533e-05],\n",
            "         [3.1493e-05],\n",
            "         [3.6804e-05],\n",
            "         [3.2013e-05],\n",
            "         [3.1181e-05],\n",
            "         [3.0626e-05],\n",
            "         [3.1761e-05],\n",
            "         [3.3764e-05],\n",
            "         [3.3396e-05],\n",
            "         [3.2393e-05],\n",
            "         [3.2240e-05],\n",
            "         [3.5627e-05],\n",
            "         [3.2459e-05],\n",
            "         [2.9585e-05],\n",
            "         [2.8604e-05],\n",
            "         [2.9865e-05],\n",
            "         [2.7698e-05],\n",
            "         [3.0172e-05],\n",
            "         [3.0311e-05],\n",
            "         [3.0233e-05],\n",
            "         [3.0710e-05],\n",
            "         [3.0145e-05],\n",
            "         [2.9135e-05],\n",
            "         [2.9953e-05],\n",
            "         [2.9513e-05],\n",
            "         [2.9887e-05],\n",
            "         [2.9546e-05],\n",
            "         [2.8133e-05],\n",
            "         [2.9841e-05],\n",
            "         [2.9719e-05],\n",
            "         [2.9901e-05],\n",
            "         [3.0102e-05],\n",
            "         [3.1428e-05],\n",
            "         [3.0370e-05],\n",
            "         [3.2051e-05],\n",
            "         [2.9836e-05],\n",
            "         [3.0164e-05],\n",
            "         [3.0462e-05],\n",
            "         [3.4689e-05],\n",
            "         [3.0279e-05],\n",
            "         [3.0645e-05],\n",
            "         [2.7801e-05],\n",
            "         [2.8662e-05],\n",
            "         [2.9670e-05],\n",
            "         [2.9947e-05],\n",
            "         [3.0289e-05],\n",
            "         [3.0152e-05],\n",
            "         [3.0498e-05],\n",
            "         [3.0567e-05],\n",
            "         [3.2129e-05],\n",
            "         [3.1072e-05],\n",
            "         [2.9974e-05],\n",
            "         [2.9561e-05],\n",
            "         [3.0362e-05],\n",
            "         [2.9901e-05],\n",
            "         [2.9528e-05],\n",
            "         [2.9438e-05],\n",
            "         [2.9167e-05],\n",
            "         [3.0034e-05],\n",
            "         [3.0462e-05],\n",
            "         [2.9562e-05],\n",
            "         [3.1872e-05],\n",
            "         [3.1138e-05],\n",
            "         [3.4738e-05],\n",
            "         [3.0347e-05],\n",
            "         [3.0462e-05],\n",
            "         [2.7864e-05],\n",
            "         [2.8125e-05],\n",
            "         [2.8030e-05],\n",
            "         [2.9383e-05],\n",
            "         [2.8026e-05],\n",
            "         [2.7867e-05],\n",
            "         [2.9658e-05],\n",
            "         [2.9779e-05],\n",
            "         [2.9920e-05],\n",
            "         [2.9974e-05],\n",
            "         [2.7740e-05],\n",
            "         [3.0507e-05],\n",
            "         [3.1967e-05],\n",
            "         [3.1667e-05],\n",
            "         [2.9769e-05],\n",
            "         [2.7841e-05],\n",
            "         [3.0422e-05],\n",
            "         [3.0087e-05],\n",
            "         [2.9541e-05],\n",
            "         [2.9296e-05],\n",
            "         [2.9403e-05],\n",
            "         [3.0058e-05],\n",
            "         [3.0234e-05],\n",
            "         [3.2263e-05],\n",
            "         [2.9747e-05],\n",
            "         [3.1909e-05],\n",
            "         [3.0620e-05],\n",
            "         [3.4931e-05],\n",
            "         [3.0355e-05],\n",
            "         [3.0932e-05],\n",
            "         [2.8145e-05],\n",
            "         [2.9941e-05],\n",
            "         [2.9374e-05],\n",
            "         [2.8172e-05],\n",
            "         [2.8091e-05],\n",
            "         [2.8041e-05],\n",
            "         [2.9426e-05],\n",
            "         [3.0334e-05],\n",
            "         [2.9943e-05],\n",
            "         [2.9437e-05],\n",
            "         [2.9731e-05],\n",
            "         [2.8848e-05],\n",
            "         [3.0404e-05],\n",
            "         [2.9073e-05],\n",
            "         [2.7561e-05],\n",
            "         [3.0127e-05],\n",
            "         [2.8707e-05],\n",
            "         [2.8887e-05],\n",
            "         [2.9281e-05],\n",
            "         [2.8971e-05],\n",
            "         [2.8094e-05],\n",
            "         [3.0058e-05],\n",
            "         [3.0594e-05],\n",
            "         [2.9718e-05],\n",
            "         [2.8677e-05],\n",
            "         [2.7878e-05],\n",
            "         [2.8409e-05],\n",
            "         [2.9188e-05],\n",
            "         [2.8006e-05],\n",
            "         [2.8137e-05],\n",
            "         [2.8068e-05],\n",
            "         [3.0225e-05],\n",
            "         [2.9840e-05],\n",
            "         [2.9588e-05],\n",
            "         [2.8816e-05],\n",
            "         [2.9293e-05],\n",
            "         [2.9601e-05],\n",
            "         [2.9867e-05],\n",
            "         [3.0110e-05],\n",
            "         [3.0106e-05],\n",
            "         [3.0625e-05],\n",
            "         [3.0277e-05],\n",
            "         [3.0555e-05],\n",
            "         [2.9590e-05],\n",
            "         [2.9758e-05],\n",
            "         [2.9520e-05],\n",
            "         [2.8382e-05],\n",
            "         [3.1060e-05],\n",
            "         [3.0149e-05],\n",
            "         [2.9841e-05],\n",
            "         [2.9447e-05],\n",
            "         [2.9490e-05],\n",
            "         [3.1143e-05],\n",
            "         [3.0091e-05],\n",
            "         [3.1870e-05],\n",
            "         [2.9425e-05],\n",
            "         [3.1895e-05],\n",
            "         [3.0782e-05],\n",
            "         [3.5026e-05],\n",
            "         [3.0448e-05],\n",
            "         [3.0953e-05],\n",
            "         [2.8167e-05],\n",
            "         [2.8148e-05],\n",
            "         [2.8331e-05],\n",
            "         [2.8143e-05],\n",
            "         [2.8179e-05],\n",
            "         [2.8067e-05],\n",
            "         [2.8110e-05],\n",
            "         [3.0470e-05],\n",
            "         [3.0287e-05],\n",
            "         [2.8234e-05],\n",
            "         [2.9262e-05],\n",
            "         [3.0588e-05],\n",
            "         [3.2763e-05],\n",
            "         [3.1216e-05],\n",
            "         [2.9816e-05],\n",
            "         [2.9848e-05],\n",
            "         [3.0071e-05],\n",
            "         [2.9701e-05],\n",
            "         [2.9374e-05],\n",
            "         [2.7633e-05],\n",
            "         [2.9587e-05],\n",
            "         [2.9635e-05],\n",
            "         [2.9661e-05],\n",
            "         [2.8208e-05],\n",
            "         [2.8800e-05],\n",
            "         [2.9931e-05],\n",
            "         [3.0290e-05],\n",
            "         [2.9662e-05],\n",
            "         [3.1905e-05],\n",
            "         [3.2665e-05],\n",
            "         [3.1701e-05],\n",
            "         [3.0644e-05],\n",
            "         [2.7793e-05],\n",
            "         [3.2520e-05],\n",
            "         [3.4534e-05],\n",
            "         [3.0212e-05],\n",
            "         [2.8227e-05],\n",
            "         [2.8064e-05],\n",
            "         [2.9243e-05],\n",
            "         [2.7944e-05],\n",
            "         [2.8347e-05],\n",
            "         [2.9830e-05],\n",
            "         [2.9657e-05],\n",
            "         [2.8191e-05],\n",
            "         [2.9964e-05],\n",
            "         [2.9012e-05],\n",
            "         [3.0590e-05],\n",
            "         [2.9968e-05],\n",
            "         [2.8947e-05],\n",
            "         [2.9858e-05],\n",
            "         [2.9295e-05],\n",
            "         [3.0136e-05],\n",
            "         [2.9791e-05],\n",
            "         [2.9303e-05],\n",
            "         [2.9320e-05],\n",
            "         [2.9921e-05],\n",
            "         [3.0090e-05],\n",
            "         [2.9332e-05],\n",
            "         [3.1588e-05],\n",
            "         [3.1229e-05],\n",
            "         [3.4869e-05],\n",
            "         [3.0355e-05],\n",
            "         [2.9250e-05],\n",
            "         [2.7692e-05],\n",
            "         [2.7819e-05],\n",
            "         [3.0309e-05],\n",
            "         [2.8955e-05],\n",
            "         [2.7929e-05],\n",
            "         [2.9076e-05],\n",
            "         [2.8131e-05],\n",
            "         [2.8022e-05],\n",
            "         [3.0490e-05],\n",
            "         [3.0706e-05],\n",
            "         [2.8107e-05],\n",
            "         [2.8094e-05],\n",
            "         [2.8174e-05],\n",
            "         [3.0701e-05],\n",
            "         [3.0419e-05],\n",
            "         [2.8481e-05],\n",
            "         [2.8567e-05],\n",
            "         [2.8435e-05],\n",
            "         [2.8625e-05],\n",
            "         [2.8479e-05],\n",
            "         [2.9730e-05],\n",
            "         [2.8451e-05],\n",
            "         [2.8299e-05],\n",
            "         [2.9164e-05],\n",
            "         [2.8025e-05],\n",
            "         [3.0510e-05],\n",
            "         [2.9375e-05],\n",
            "         [2.9276e-05],\n",
            "         [2.8085e-05],\n",
            "         [2.7866e-05],\n",
            "         [3.0224e-05],\n",
            "         [2.7851e-05],\n",
            "         [2.8053e-05],\n",
            "         [2.9995e-05],\n",
            "         [2.7475e-05],\n",
            "         [2.9294e-05],\n",
            "         [2.9367e-05],\n",
            "         [2.9690e-05],\n",
            "         [3.0158e-05],\n",
            "         [2.9597e-05],\n",
            "         [2.9918e-05],\n",
            "         [3.0351e-05],\n",
            "         [3.1606e-05],\n",
            "         [3.0447e-05],\n",
            "         [3.0426e-05],\n",
            "         [2.7771e-05],\n",
            "         [2.8781e-05],\n",
            "         [3.4920e-05],\n",
            "         [3.0497e-05],\n",
            "         [3.0990e-05],\n",
            "         [2.8393e-05],\n",
            "         [2.8158e-05],\n",
            "         [2.9309e-05],\n",
            "         [2.8927e-05],\n",
            "         [2.8151e-05],\n",
            "         [2.7978e-05],\n",
            "         [2.7866e-05],\n",
            "         [2.9413e-05],\n",
            "         [3.0187e-05],\n",
            "         [3.0502e-05],\n",
            "         [3.0147e-05],\n",
            "         [2.8765e-05],\n",
            "         [3.0552e-05],\n",
            "         [3.5144e-05],\n",
            "         [2.9987e-05],\n",
            "         [2.9208e-05],\n",
            "         [2.8149e-05],\n",
            "         [2.7943e-05],\n",
            "         [2.7871e-05],\n",
            "         [2.9960e-05],\n",
            "         [3.0060e-05],\n",
            "         [2.7936e-05],\n",
            "         [2.9587e-05],\n",
            "         [2.7619e-05],\n",
            "         [2.7731e-05],\n",
            "         [2.9489e-05],\n",
            "         [3.0080e-05],\n",
            "         [3.0204e-05],\n",
            "         [2.9820e-05],\n",
            "         [2.9879e-05],\n",
            "         [3.1013e-05],\n",
            "         [3.1049e-05],\n",
            "         [3.5040e-05],\n",
            "         [3.0280e-05],\n",
            "         [2.7937e-05],\n",
            "         [2.7890e-05],\n",
            "         [3.0529e-05],\n",
            "         [2.8167e-05],\n",
            "         [2.8013e-05],\n",
            "         [3.0007e-05],\n",
            "         [2.8394e-05],\n",
            "         [2.7819e-05],\n",
            "         [2.9184e-05],\n",
            "         [2.7394e-05],\n",
            "         [2.9288e-05],\n",
            "         [3.0232e-05],\n",
            "         [2.9996e-05],\n",
            "         [2.9828e-05],\n",
            "         [2.9529e-05],\n",
            "         [3.0596e-05],\n",
            "         [3.0242e-05],\n",
            "         [3.1277e-05],\n",
            "         [2.8070e-05],\n",
            "         [2.7951e-05],\n",
            "         [2.7941e-05],\n",
            "         [2.9224e-05],\n",
            "         [2.9441e-05],\n",
            "         [2.8448e-05],\n",
            "         [2.8127e-05],\n",
            "         [2.8028e-05],\n",
            "         [2.8804e-05],\n",
            "         [2.9487e-05],\n",
            "         [2.9608e-05],\n",
            "         [3.0835e-05],\n",
            "         [2.7840e-05],\n",
            "         [2.9035e-05],\n",
            "         [2.9931e-05],\n",
            "         [2.9611e-05],\n",
            "         [2.8644e-05],\n",
            "         [2.9397e-05],\n",
            "         [2.8522e-05],\n",
            "         [2.9228e-05],\n",
            "         [2.9749e-05],\n",
            "         [2.8852e-05],\n",
            "         [2.7593e-05],\n",
            "         [2.9812e-05],\n",
            "         [2.8649e-05],\n",
            "         [3.0441e-05],\n",
            "         [3.0739e-05],\n",
            "         [2.8363e-05],\n",
            "         [2.8429e-05],\n",
            "         [2.9587e-05],\n",
            "         [2.8832e-05],\n",
            "         [2.8833e-05],\n",
            "         [2.8967e-05],\n",
            "         [2.8731e-05],\n",
            "         [2.8592e-05],\n",
            "         [3.0575e-05],\n",
            "         [2.8854e-05],\n",
            "         [2.8565e-05],\n",
            "         [2.8448e-05],\n",
            "         [2.8304e-05],\n",
            "         [3.0893e-05],\n",
            "         [2.9657e-05],\n",
            "         [2.9793e-05],\n",
            "         [2.8444e-05],\n",
            "         [2.7979e-05],\n",
            "         [3.0082e-05],\n",
            "         [2.9155e-05],\n",
            "         [2.7657e-05],\n",
            "         [2.8959e-05],\n",
            "         [2.8459e-05],\n",
            "         [2.8439e-05],\n",
            "         [2.9091e-05],\n",
            "         [2.8066e-05],\n",
            "         [2.8869e-05],\n",
            "         [3.0118e-05],\n",
            "         [2.8835e-05],\n",
            "         [2.9559e-05],\n",
            "         [2.9512e-05],\n",
            "         [3.0923e-05],\n",
            "         [3.4749e-05],\n",
            "         [3.1117e-05],\n",
            "         [3.0319e-05],\n",
            "         [2.7929e-05],\n",
            "         [2.7943e-05],\n",
            "         [3.0093e-05],\n",
            "         [2.7910e-05],\n",
            "         [2.9752e-05],\n",
            "         [2.9745e-05],\n",
            "         [3.1450e-05],\n",
            "         [3.0154e-05],\n",
            "         [2.9928e-05],\n",
            "         [2.9408e-05],\n",
            "         [2.8123e-05],\n",
            "         [2.9778e-05],\n",
            "         [2.9503e-05],\n",
            "         [2.9131e-05],\n",
            "         [3.0159e-05],\n",
            "         [3.0392e-05],\n",
            "         [2.7907e-05],\n",
            "         [2.7943e-05],\n",
            "         [3.0878e-05],\n",
            "         [3.0346e-05],\n",
            "         [3.0844e-05],\n",
            "         [2.8116e-05],\n",
            "         [2.8025e-05],\n",
            "         [2.9378e-05],\n",
            "         [2.7989e-05],\n",
            "         [2.8622e-05],\n",
            "         [2.9666e-05],\n",
            "         [2.9507e-05],\n",
            "         [2.9698e-05],\n",
            "         [2.8833e-05],\n",
            "         [3.0482e-05],\n",
            "         [3.0239e-05],\n",
            "         [2.9582e-05],\n",
            "         [2.9363e-05],\n",
            "         [2.9392e-05],\n",
            "         [2.9913e-05],\n",
            "         [2.9844e-05],\n",
            "         [2.9411e-05],\n",
            "         [2.9061e-05],\n",
            "         [2.9444e-05],\n",
            "         [2.9909e-05],\n",
            "         [3.0010e-05],\n",
            "         [3.1089e-05],\n",
            "         [2.9592e-05],\n",
            "         [3.1166e-05],\n",
            "         [3.0855e-05],\n",
            "         [3.4609e-05],\n",
            "         [3.0185e-05],\n",
            "         [3.0130e-05],\n",
            "         [2.7780e-05],\n",
            "         [2.8966e-05],\n",
            "         [3.5097e-05],\n",
            "         [3.0256e-05],\n",
            "         [3.0930e-05],\n",
            "         [2.8647e-05],\n",
            "         [2.8518e-05],\n",
            "         [2.8637e-05],\n",
            "         [2.8368e-05],\n",
            "         [2.8389e-05],\n",
            "         [2.8311e-05],\n",
            "         [2.9125e-05],\n",
            "         [2.9704e-05],\n",
            "         [2.7977e-05],\n",
            "         [3.0008e-05],\n",
            "         [3.0633e-05],\n",
            "         [3.0429e-05],\n",
            "         [3.1775e-05],\n",
            "         [3.1898e-05],\n",
            "         [2.9949e-05],\n",
            "         [2.8570e-05],\n",
            "         [2.9954e-05],\n",
            "         [2.9906e-05],\n",
            "         [2.7576e-05],\n",
            "         [2.9992e-05],\n",
            "         [3.0013e-05],\n",
            "         [2.9528e-05],\n",
            "         [2.9168e-05],\n",
            "         [2.9244e-05],\n",
            "         [2.9983e-05],\n",
            "         [3.0230e-05],\n",
            "         [2.9352e-05],\n",
            "         [3.1583e-05],\n",
            "         [3.1288e-05],\n",
            "         [3.4785e-05],\n",
            "         [3.0123e-05],\n",
            "         [3.0260e-05],\n",
            "         [2.8034e-05],\n",
            "         [2.8002e-05],\n",
            "         [2.8191e-05],\n",
            "         [2.8102e-05],\n",
            "         [2.9174e-05],\n",
            "         [2.9537e-05],\n",
            "         [2.7765e-05],\n",
            "         [2.8637e-05],\n",
            "         [2.9581e-05],\n",
            "         [3.0292e-05],\n",
            "         [3.0872e-05],\n",
            "         [3.0051e-05],\n",
            "         [2.9687e-05],\n",
            "         [2.8538e-05],\n",
            "         [2.9684e-05],\n",
            "         [3.2281e-05],\n",
            "         [2.8885e-05],\n",
            "         [2.7580e-05],\n",
            "         [2.7448e-05],\n",
            "         [2.9446e-05],\n",
            "         [2.9702e-05],\n",
            "         [3.0164e-05],\n",
            "         [3.0372e-05],\n",
            "         [2.9722e-05],\n",
            "         [3.0025e-05],\n",
            "         [2.8014e-05],\n",
            "         [3.1249e-05],\n",
            "         [3.5440e-05],\n",
            "         [2.8929e-05],\n",
            "         [3.0088e-05],\n",
            "         [4.3119e-05],\n",
            "         [5.9535e-05],\n",
            "         [1.1428e-04],\n",
            "         [6.3441e-04]]], device='cuda:0')\n",
            "Tokens: ['[CLS]', 'bert', 'is', 'a', 'powerful', 'model', 'for', 'natural', 'language', 'understanding', '.', 'it', 'has', 'revolution', '##ized', 'many', 'nl', '##p', 'tasks', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "Keywords: [('[CLS]', 0.00144849659409374), ('bert', 0.0002321266510989517), ('is', 5.8635196182876825e-05), ('a', 3.7038378650322556e-05), ('powerful', 3.2713091059122235e-05), ('model', 3.2062645914265886e-05), ('for', 3.2948908483376727e-05), ('natural', 3.181899228366092e-05), ('language', 3.353316060383804e-05), ('understanding', 3.149322947137989e-05), ('.', 3.680430745589547e-05), ('it', 3.201345316483639e-05), ('has', 3.118109088973142e-05), ('revolution', 3.0626164516434073e-05), ('##ized', 3.1761028367327526e-05), ('many', 3.376390668563545e-05), ('nl', 3.3395994250895455e-05), ('##p', 3.239278157707304e-05), ('tasks', 3.224001557100564e-05), ('.', 3.562688289093785e-05), ('[SEP]', 3.245858533773571e-05), ('[PAD]', 2.9585491574835032e-05), ('[PAD]', 2.8604255930986255e-05), ('[PAD]', 2.986530671478249e-05), ('[PAD]', 2.769848106254358e-05), ('[PAD]', 3.0171813705237582e-05), ('[PAD]', 3.0311168302432634e-05), ('[PAD]', 3.023330464202445e-05), ('[PAD]', 3.071048195124604e-05), ('[PAD]', 3.0144723496050574e-05), ('[PAD]', 2.9134604119462892e-05), ('[PAD]', 2.99531857308466e-05), ('[PAD]', 2.9512957553379238e-05), ('[PAD]', 2.9886930860811844e-05), ('[PAD]', 2.954618503281381e-05), ('[PAD]', 2.8133445084677078e-05), ('[PAD]', 2.9841305149602704e-05), ('[PAD]', 2.9719245503656566e-05), ('[PAD]', 2.990118446177803e-05), ('[PAD]', 3.0101577067398466e-05), ('[PAD]', 3.142848436255008e-05), ('[PAD]', 3.037027818209026e-05), ('[PAD]', 3.2050811569206417e-05), ('[PAD]', 2.9835842724423856e-05), ('[PAD]', 3.016430673596915e-05), ('[PAD]', 3.046211350010708e-05), ('[PAD]', 3.468909199000336e-05), ('[PAD]', 3.02785756502999e-05), ('[PAD]', 3.064535849262029e-05), ('[PAD]', 2.7800999305327423e-05), ('[PAD]', 2.866170325432904e-05), ('[PAD]', 2.966968713735696e-05), ('[PAD]', 2.994727219629567e-05), ('[PAD]', 3.028880018973723e-05), ('[PAD]', 3.0151966711855493e-05), ('[PAD]', 3.049763290619012e-05), ('[PAD]', 3.056652349187061e-05), ('[PAD]', 3.2128573366208e-05), ('[PAD]', 3.1072060664882883e-05), ('[PAD]', 2.997407500515692e-05), ('[PAD]', 2.956067146442365e-05), ('[PAD]', 3.0361852623173036e-05), ('[PAD]', 2.9901242669438943e-05), ('[PAD]', 2.952798968181014e-05), ('[PAD]', 2.943782055808697e-05), ('[PAD]', 2.9166652893763967e-05), ('[PAD]', 3.0033901566639543e-05), ('[PAD]', 3.0461504138656892e-05), ('[PAD]', 2.956236494355835e-05), ('[PAD]', 3.1871684768702835e-05), ('[PAD]', 3.113755883532576e-05), ('[PAD]', 3.473785545793362e-05), ('[PAD]', 3.0347318897838704e-05), ('[PAD]', 3.0461735150311142e-05), ('[PAD]', 2.7864196454174817e-05), ('[PAD]', 2.8125370590714738e-05), ('[PAD]', 2.8029971872456372e-05), ('[PAD]', 2.938323814305477e-05), ('[PAD]', 2.8025957362842746e-05), ('[PAD]', 2.786735785775818e-05), ('[PAD]', 2.965769454021938e-05), ('[PAD]', 2.9779219403280877e-05), ('[PAD]', 2.991964174725581e-05), ('[PAD]', 2.997358751599677e-05), ('[PAD]', 2.7739824872696772e-05), ('[PAD]', 3.0507435440085828e-05), ('[PAD]', 3.196732359356247e-05), ('[PAD]', 3.1667361326981336e-05), ('[PAD]', 2.9769251341349445e-05), ('[PAD]', 2.7841009796247818e-05), ('[PAD]', 3.0421611882047728e-05), ('[PAD]', 3.0086852348176762e-05), ('[PAD]', 2.9540889954660088e-05), ('[PAD]', 2.9295639251358807e-05), ('[PAD]', 2.9402610380202532e-05), ('[PAD]', 3.0057855838094838e-05), ('[PAD]', 3.0234434234444052e-05), ('[PAD]', 3.2262716558761895e-05), ('[PAD]', 2.9746834115940146e-05), ('[PAD]', 3.190933421137743e-05), ('[PAD]', 3.062032556044869e-05), ('[PAD]', 3.493079202598892e-05), ('[PAD]', 3.0354731279658154e-05), ('[PAD]', 3.0931922083254904e-05), ('[PAD]', 2.814528124872595e-05), ('[PAD]', 2.994133137690369e-05), ('[PAD]', 2.9373688448686153e-05), ('[PAD]', 2.8172296879347414e-05), ('[PAD]', 2.8091326385037974e-05), ('[PAD]', 2.8041227778885514e-05), ('[PAD]', 2.942572427855339e-05), ('[PAD]', 3.033424036402721e-05), ('[PAD]', 2.99426192214014e-05), ('[PAD]', 2.9436669137794524e-05), ('[PAD]', 2.9731038011959754e-05), ('[PAD]', 2.8848340662079863e-05), ('[PAD]', 3.040389492525719e-05), ('[PAD]', 2.9072929464746267e-05), ('[PAD]', 2.7561356546357274e-05), ('[PAD]', 3.012661727552768e-05), ('[PAD]', 2.8707139790640213e-05), ('[PAD]', 2.888737799366936e-05), ('[PAD]', 2.928061076090671e-05), ('[PAD]', 2.8971024221391417e-05), ('[PAD]', 2.8094465960748494e-05), ('[PAD]', 3.005800135724712e-05), ('[PAD]', 3.059384835069068e-05), ('[PAD]', 2.97178266919218e-05), ('[PAD]', 2.867728835553862e-05), ('[PAD]', 2.7878149921889417e-05), ('[PAD]', 2.840890192601364e-05), ('[PAD]', 2.9188498956500553e-05), ('[PAD]', 2.8006403226754628e-05), ('[PAD]', 2.8137174012954347e-05), ('[PAD]', 2.8068114261259325e-05), ('[PAD]', 3.0224571673898026e-05), ('[PAD]', 2.9839684430044144e-05), ('[PAD]', 2.9588480174425058e-05), ('[PAD]', 2.8816361009376124e-05), ('[PAD]', 2.9293487386894412e-05), ('[PAD]', 2.96005055133719e-05), ('[PAD]', 2.986681465699803e-05), ('[PAD]', 3.011007356690243e-05), ('[PAD]', 3.010573891515378e-05), ('[PAD]', 3.062473115278408e-05), ('[PAD]', 3.027696038770955e-05), ('[PAD]', 3.055507113458589e-05), ('[PAD]', 2.958955337817315e-05), ('[PAD]', 2.9758410164504312e-05), ('[PAD]', 2.95196587103419e-05), ('[PAD]', 2.838166074070614e-05), ('[PAD]', 3.105976793449372e-05), ('[PAD]', 3.0149269150570035e-05), ('[PAD]', 2.9841194191249087e-05), ('[PAD]', 2.944745028798934e-05), ('[PAD]', 2.9490029191947542e-05), ('[PAD]', 3.114323044428602e-05), ('[PAD]', 3.0091474400251172e-05), ('[PAD]', 3.186958565493114e-05), ('[PAD]', 2.9425358661683276e-05), ('[PAD]', 3.1894975109025836e-05), ('[PAD]', 3.07816153508611e-05), ('[PAD]', 3.502622348605655e-05), ('[PAD]', 3.0448229153989814e-05), ('[PAD]', 3.0952698580222204e-05), ('[PAD]', 2.816708365571685e-05), ('[PAD]', 2.814753861457575e-05), ('[PAD]', 2.8330874556559138e-05), ('[PAD]', 2.8143134841229767e-05), ('[PAD]', 2.8179441869724542e-05), ('[PAD]', 2.806679913192056e-05), ('[PAD]', 2.810976729961112e-05), ('[PAD]', 3.0469696866930462e-05), ('[PAD]', 3.02865792036755e-05), ('[PAD]', 2.823442810040433e-05), ('[PAD]', 2.9261795134516433e-05), ('[PAD]', 3.058827496715821e-05), ('[PAD]', 3.2762702176114544e-05), ('[PAD]', 3.121646659565158e-05), ('[PAD]', 2.981610487040598e-05), ('[PAD]', 2.9847937184968032e-05), ('[PAD]', 3.0070616048760712e-05), ('[PAD]', 2.9700546292588115e-05), ('[PAD]', 2.937402496172581e-05), ('[PAD]', 2.7632995625026524e-05), ('[PAD]', 2.958684490295127e-05), ('[PAD]', 2.963496262964327e-05), ('[PAD]', 2.966077772725839e-05), ('[PAD]', 2.820761983457487e-05), ('[PAD]', 2.8799961000913754e-05), ('[PAD]', 2.9930801247246563e-05), ('[PAD]', 3.0289724236354232e-05), ('[PAD]', 2.9661821827176027e-05), ('[PAD]', 3.1905408832244575e-05), ('[PAD]', 3.266470957896672e-05), ('[PAD]', 3.170144555042498e-05), ('[PAD]', 3.064401607844047e-05), ('[PAD]', 2.7793284971266985e-05), ('[PAD]', 3.251974703744054e-05), ('[PAD]', 3.4534125006757677e-05), ('[PAD]', 3.021160591742955e-05), ('[PAD]', 2.822675378411077e-05), ('[PAD]', 2.806401789712254e-05), ('[PAD]', 2.9242632081150077e-05), ('[PAD]', 2.7944000976276584e-05), ('[PAD]', 2.8346661565592512e-05), ('[PAD]', 2.9829952836735174e-05), ('[PAD]', 2.9656786864507012e-05), ('[PAD]', 2.819078326865565e-05), ('[PAD]', 2.9964156055939384e-05), ('[PAD]', 2.9011749575147405e-05), ('[PAD]', 3.0590086680604145e-05), ('[PAD]', 2.996769944729749e-05), ('[PAD]', 2.89468025584938e-05), ('[PAD]', 2.9858070774935186e-05), ('[PAD]', 2.9295413696672767e-05), ('[PAD]', 3.0135526685626246e-05), ('[PAD]', 2.9791177439619787e-05), ('[PAD]', 2.9302818802534603e-05), ('[PAD]', 2.931972994701937e-05), ('[PAD]', 2.9921297027613036e-05), ('[PAD]', 3.0089864594629034e-05), ('[PAD]', 2.933164250862319e-05), ('[PAD]', 3.158824983984232e-05), ('[PAD]', 3.122918133158237e-05), ('[PAD]', 3.486935020191595e-05), ('[PAD]', 3.0354613045346923e-05), ('[PAD]', 2.9249575163703412e-05), ('[PAD]', 2.769203274510801e-05), ('[PAD]', 2.7819005481433123e-05), ('[PAD]', 3.0308505301945843e-05), ('[PAD]', 2.895528268709313e-05), ('[PAD]', 2.79289779427927e-05), ('[PAD]', 2.9076423743390478e-05), ('[PAD]', 2.8130551072536036e-05), ('[PAD]', 2.802240487653762e-05), ('[PAD]', 3.0489925848087296e-05), ('[PAD]', 3.070632374146953e-05), ('[PAD]', 2.8106655008741654e-05), ('[PAD]', 2.809422221616842e-05), ('[PAD]', 2.8174417820991948e-05), ('[PAD]', 3.0700877687195316e-05), ('[PAD]', 3.0418568712775595e-05), ('[PAD]', 2.848084295692388e-05), ('[PAD]', 2.8566637411131524e-05), ('[PAD]', 2.8435168133000843e-05), ('[PAD]', 2.862496694433503e-05), ('[PAD]', 2.8478887543315068e-05), ('[PAD]', 2.973007212858647e-05), ('[PAD]', 2.84507914329879e-05), ('[PAD]', 2.829936238413211e-05), ('[PAD]', 2.9164015359128825e-05), ('[PAD]', 2.8024624043609947e-05), ('[PAD]', 3.0509881980833597e-05), ('[PAD]', 2.9374890800681897e-05), ('[PAD]', 2.9275528504513204e-05), ('[PAD]', 2.8084954465157352e-05), ('[PAD]', 2.7865658921655267e-05), ('[PAD]', 3.0224053261918016e-05), ('[PAD]', 2.7850725018652156e-05), ('[PAD]', 2.8053047572029755e-05), ('[PAD]', 2.999474963871762e-05), ('[PAD]', 2.7475307433633134e-05), ('[PAD]', 2.9293571060406975e-05), ('[PAD]', 2.936741293524392e-05), ('[PAD]', 2.969001252495218e-05), ('[PAD]', 3.0158411391312256e-05), ('[PAD]', 2.9596836611744948e-05), ('[PAD]', 2.991841574839782e-05), ('[PAD]', 3.0350909582921304e-05), ('[PAD]', 3.160617779940367e-05), ('[PAD]', 3.044712866540067e-05), ('[PAD]', 3.0425677323364653e-05), ('[PAD]', 2.777084409899544e-05), ('[PAD]', 2.878065970435273e-05), ('[PAD]', 3.492030009510927e-05), ('[PAD]', 3.0497429179376923e-05), ('[PAD]', 3.0989824153948575e-05), ('[PAD]', 2.8392707463353872e-05), ('[PAD]', 2.8157523047411814e-05), ('[PAD]', 2.9308941520866938e-05), ('[PAD]', 2.892740667448379e-05), ('[PAD]', 2.8150865546194836e-05), ('[PAD]', 2.7978398065897636e-05), ('[PAD]', 2.786592267511878e-05), ('[PAD]', 2.941281854873523e-05), ('[PAD]', 3.0186811272869818e-05), ('[PAD]', 3.0501851142616943e-05), ('[PAD]', 3.0146935387165286e-05), ('[PAD]', 2.8765267416019924e-05), ('[PAD]', 3.055209890590049e-05), ('[PAD]', 3.514383206493221e-05), ('[PAD]', 2.9986682420712896e-05), ('[PAD]', 2.920765291491989e-05), ('[PAD]', 2.8149175705038942e-05), ('[PAD]', 2.7942720407736488e-05), ('[PAD]', 2.7870628400705755e-05), ('[PAD]', 2.9959528546896763e-05), ('[PAD]', 3.0060238714213483e-05), ('[PAD]', 2.7936459446209483e-05), ('[PAD]', 2.9587381504825316e-05), ('[PAD]', 2.7619269530987367e-05), ('[PAD]', 2.773072264972143e-05), ('[PAD]', 2.9489128792192787e-05), ('[PAD]', 3.007976738444995e-05), ('[PAD]', 3.020365329575725e-05), ('[PAD]', 2.982019941555336e-05), ('[PAD]', 2.9878809073125012e-05), ('[PAD]', 3.101303445873782e-05), ('[PAD]', 3.104883944615722e-05), ('[PAD]', 3.5040291550103575e-05), ('[PAD]', 3.0279847123892978e-05), ('[PAD]', 2.79366213362664e-05), ('[PAD]', 2.7890169803868048e-05), ('[PAD]', 3.052856482099742e-05), ('[PAD]', 2.8166788979433477e-05), ('[PAD]', 2.801257505780086e-05), ('[PAD]', 3.0007164241396822e-05), ('[PAD]', 2.839416811184492e-05), ('[PAD]', 2.7818714443128556e-05), ('[PAD]', 2.9184431696194224e-05), ('[PAD]', 2.7394440621719696e-05), ('[PAD]', 2.9288121368153952e-05), ('[PAD]', 3.0231894925236702e-05), ('[PAD]', 2.9996064768056385e-05), ('[PAD]', 2.982804835482966e-05), ('[PAD]', 2.952900467789732e-05), ('[PAD]', 3.059600931010209e-05), ('[PAD]', 3.024158468178939e-05), ('[PAD]', 3.127704621874727e-05), ('[PAD]', 2.806958400469739e-05), ('[PAD]', 2.7950609364779666e-05), ('[PAD]', 2.7940750442212448e-05), ('[PAD]', 2.922403837146703e-05), ('[PAD]', 2.9440938305924647e-05), ('[PAD]', 2.8448323064367287e-05), ('[PAD]', 2.8126876713940874e-05), ('[PAD]', 2.802759081532713e-05), ('[PAD]', 2.8804464818676934e-05), ('[PAD]', 2.9486849598470144e-05), ('[PAD]', 2.9608325348817743e-05), ('[PAD]', 3.083514820900746e-05), ('[PAD]', 2.7839812901220284e-05), ('[PAD]', 2.903502718254458e-05), ('[PAD]', 2.993145608343184e-05), ('[PAD]', 2.961092468467541e-05), ('[PAD]', 2.8644273697864264e-05), ('[PAD]', 2.9397031539701857e-05), ('[PAD]', 2.8522481443360448e-05), ('[PAD]', 2.922816202044487e-05), ('[PAD]', 2.97492733807303e-05), ('[PAD]', 2.8852469768025912e-05), ('[PAD]', 2.759254857664928e-05), ('[PAD]', 2.981235047627706e-05), ('[PAD]', 2.864929956558626e-05), ('[PAD]', 3.0440563932643272e-05), ('[PAD]', 3.07389345834963e-05), ('[PAD]', 2.83630706690019e-05), ('[PAD]', 2.8428552468540147e-05), ('[PAD]', 2.9586984965135343e-05), ('[PAD]', 2.8831536837969907e-05), ('[PAD]', 2.8833377655246295e-05), ('[PAD]', 2.8967324396944605e-05), ('[PAD]', 2.8730775738949887e-05), ('[PAD]', 2.859233609342482e-05), ('[PAD]', 3.057465801248327e-05), ('[PAD]', 2.8854008633061312e-05), ('[PAD]', 2.8565218599396758e-05), ('[PAD]', 2.8447997465264052e-05), ('[PAD]', 2.830435914802365e-05), ('[PAD]', 3.089333404204808e-05), ('[PAD]', 2.9656814149348065e-05), ('[PAD]', 2.9792852728860453e-05), ('[PAD]', 2.8443819246604107e-05), ('[PAD]', 2.79792511719279e-05), ('[PAD]', 3.008154635608662e-05), ('[PAD]', 2.9155169613659382e-05), ('[PAD]', 2.76571972790407e-05), ('[PAD]', 2.8958706025150605e-05), ('[PAD]', 2.8459229724830948e-05), ('[PAD]', 2.843891161319334e-05), ('[PAD]', 2.909076283685863e-05), ('[PAD]', 2.8065784135833383e-05), ('[PAD]', 2.8868978915852495e-05), ('[PAD]', 3.0117855203570798e-05), ('[PAD]', 2.8835469493060373e-05), ('[PAD]', 2.955883974209428e-05), ('[PAD]', 2.9511662432923913e-05), ('[PAD]', 3.0922899895813316e-05), ('[PAD]', 3.4748918551485986e-05), ('[PAD]', 3.111681144218892e-05), ('[PAD]', 3.0318627977976575e-05), ('[PAD]', 2.7929401767323725e-05), ('[PAD]', 2.7942509404965676e-05), ('[PAD]', 3.0093136956566013e-05), ('[PAD]', 2.7909965865546837e-05), ('[PAD]', 2.9751628972007893e-05), ('[PAD]', 2.974493327201344e-05), ('[PAD]', 3.145016307826154e-05), ('[PAD]', 3.0154038540786132e-05), ('[PAD]', 2.9928258300060406e-05), ('[PAD]', 2.9408220143523067e-05), ('[PAD]', 2.8122583898948506e-05), ('[PAD]', 2.9777940653730184e-05), ('[PAD]', 2.95034478767775e-05), ('[PAD]', 2.9131404517102055e-05), ('[PAD]', 3.0159042580635287e-05), ('[PAD]', 3.0392036933335476e-05), ('[PAD]', 2.7907035473617725e-05), ('[PAD]', 2.794266947603319e-05), ('[PAD]', 3.087787263211794e-05), ('[PAD]', 3.0345523555297405e-05), ('[PAD]', 3.0844144930597395e-05), ('[PAD]', 2.8115771783632226e-05), ('[PAD]', 2.8025317078572698e-05), ('[PAD]', 2.9378055842244066e-05), ('[PAD]', 2.7989288355456665e-05), ('[PAD]', 2.8621747333090752e-05), ('[PAD]', 2.9665503461728804e-05), ('[PAD]', 2.9507022190955468e-05), ('[PAD]', 2.9698052458115853e-05), ('[PAD]', 2.8832773750764318e-05), ('[PAD]', 3.048184407816734e-05), ('[PAD]', 3.0239016268751584e-05), ('[PAD]', 2.958170989586506e-05), ('[PAD]', 2.936318560387008e-05), ('[PAD]', 2.939176010841038e-05), ('[PAD]', 2.9912534955656156e-05), ('[PAD]', 2.9844095479347743e-05), ('[PAD]', 2.941057573480066e-05), ('[PAD]', 2.9060596716590226e-05), ('[PAD]', 2.94439414574299e-05), ('[PAD]', 2.990934081026353e-05), ('[PAD]', 3.0010227419552393e-05), ('[PAD]', 3.1089133699424565e-05), ('[PAD]', 2.9592207283712924e-05), ('[PAD]', 3.116649531875737e-05), ('[PAD]', 3.085514981648885e-05), ('[PAD]', 3.4609030990395695e-05), ('[PAD]', 3.018540155608207e-05), ('[PAD]', 3.0129720471450128e-05), ('[PAD]', 2.777963709377218e-05), ('[PAD]', 2.896641308325343e-05), ('[PAD]', 3.509677480906248e-05), ('[PAD]', 3.0255831006797962e-05), ('[PAD]', 3.0929921194911e-05), ('[PAD]', 2.8647335057030432e-05), ('[PAD]', 2.8517535611172207e-05), ('[PAD]', 2.8637088689720258e-05), ('[PAD]', 2.8367643608362414e-05), ('[PAD]', 2.8389104045345448e-05), ('[PAD]', 2.8310727429925464e-05), ('[PAD]', 2.9125323635526e-05), ('[PAD]', 2.9704398912144825e-05), ('[PAD]', 2.797722481773235e-05), ('[PAD]', 3.0008251997060142e-05), ('[PAD]', 3.0632967536803335e-05), ('[PAD]', 3.042915886908304e-05), ('[PAD]', 3.17748126690276e-05), ('[PAD]', 3.189847484463826e-05), ('[PAD]', 2.99486728181364e-05), ('[PAD]', 2.856979517673608e-05), ('[PAD]', 2.9954440833535045e-05), ('[PAD]', 2.9905522751505487e-05), ('[PAD]', 2.7575608328334056e-05), ('[PAD]', 2.999208663823083e-05), ('[PAD]', 3.001271943503525e-05), ('[PAD]', 2.9527824153774418e-05), ('[PAD]', 2.916807534347754e-05), ('[PAD]', 2.9244138204376213e-05), ('[PAD]', 2.9983051717863418e-05), ('[PAD]', 3.0229992262320593e-05), ('[PAD]', 2.9352209821809083e-05), ('[PAD]', 3.1583487725583836e-05), ('[PAD]', 3.128823300357908e-05), ('[PAD]', 3.478536018519662e-05), ('[PAD]', 3.0123430406092666e-05), ('[PAD]', 3.025992918992415e-05), ('[PAD]', 2.8033897251589224e-05), ('[PAD]', 2.8002077669952996e-05), ('[PAD]', 2.8191243472974747e-05), ('[PAD]', 2.8102182113798335e-05), ('[PAD]', 2.917363599408418e-05), ('[PAD]', 2.9537230147980154e-05), ('[PAD]', 2.776549445115961e-05), ('[PAD]', 2.86370595858898e-05), ('[PAD]', 2.9580893169622868e-05), ('[PAD]', 3.0292327210190706e-05), ('[PAD]', 3.0872102797729895e-05), ('[PAD]', 3.0050867280806415e-05), ('[PAD]', 2.9687238566111773e-05), ('[PAD]', 2.8538262995425612e-05), ('[PAD]', 2.9683724278584123e-05), ('[PAD]', 3.2281117455568165e-05), ('[PAD]', 2.8885200663353316e-05), ('[PAD]', 2.7579921152209863e-05), ('[PAD]', 2.7448411856312305e-05), ('[PAD]', 2.944593688880559e-05), ('[PAD]', 2.970207242469769e-05), ('[PAD]', 3.016439040948171e-05), ('[PAD]', 3.0371928005479276e-05), ('[PAD]', 2.9722081308136694e-05), ('[PAD]', 3.0025084925000556e-05), ('[PAD]', 2.8014284907840192e-05), ('[PAD]', 3.12494084937498e-05), ('[PAD]', 3.54395633621607e-05), ('[PAD]', 2.8929198379046284e-05), ('[PAD]', 3.008785643032752e-05), ('[PAD]', 4.311935117584653e-05), ('[PAD]', 5.95351739320904e-05), ('[PAD]', 0.00011427919525885954), ('[PAD]', 0.0006344137946143746)]\n",
            "Top Keywords: [('[CLS]', 0.00144849659409374), ('[PAD]', 0.0006344137946143746), ('bert', 0.0002321266510989517), ('[PAD]', 0.00011427919525885954), ('[PAD]', 5.95351739320904e-05), ('is', 5.8635196182876825e-05), ('[PAD]', 4.311935117584653e-05), ('a', 3.7038378650322556e-05), ('.', 3.680430745589547e-05), ('.', 3.562688289093785e-05)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "36pGr3q8tdQR",
        "outputId": "2b5afdb3-3ae9-4a3e-9e27-cae080646527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'keywords' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-229fb5d42b70>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Sort the probabilities in descending order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keywords' is not defined"
          ]
        }
      ]
    }
  ]
}